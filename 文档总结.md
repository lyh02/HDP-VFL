## 多方场景下纵向逻辑回归模型

> 这里假设是两方来联合训练一个模型。在联邦学习中，有以下几种角色：
>
> guest:数据应用方，在纵向FL中指的是含有数据标签的一方。而且建模流程一般由guest方发起
>
> host：数据的提供方
>
> arbiter:主要来辅助多方联合建模的。纵向FL中用来分发公私钥、加解密服务等等。它本身既不提供数据，也不使用数据

### 多方场景一：纵向逻辑回归（使用同态加密来保护数据隐私）

**首先要明确最终的目标**：最终我要得到两个子模型，对于guest方(为了公式描述方便，以下也叫做A方)而言，我要得到子模型$w_A$；对于host方而言，我要得到子模型(为了公式描述方便，以下也叫做B方)$\omega_B$

这也意味着当我使用模型进行预测的时候，我需要联合两个子模型$\omega_A和\omega_B$才可以进行预测



#### 损失函数

$$
F(\omega)=\frac{1}{n}\sum_{n=1}^{n}log(1+e^{-y_i\omega^Tx_i})
$$

> 这里损失函数形式和单方场景下略有区别，多方交互的联邦学习中逻辑回归函数都是这个形式的损失函数。我也不太清楚这样的好处

#### 上述损失函数的梯度公式是

$$
\nabla F(\omega) = \frac{1}{n}\sum_{n=1}^{n}(\frac{1}{1+e^{-y_i\omega^Tx_i}}-1)y_ix_i
$$

由于同态加密不支持指数运算，所以需要将上述的指数形式近似转化为**多项式**才可以使用同态加密技术

所以损失函数的梯度公式可以**近似**的写成
$$
\nabla F(\omega) \approx \frac{1}{n}\sum_{n=1}^{n}(0.25\omega^Tx_i-0.5y_i)x_i = \frac{1}{n}\sum_{n=1}^{n}d_ix_i
$$
在纵向联邦学习（使用同态加密技术）的场景下，guest方拥有数据$X_A$，以及数据标签$Y$。host方(为了公式描述方便，以下也叫做B方)拥有数据$X_B$

所以完整的$\omega x = \omega_A X_A + \omega_B X_B$

这里有一个符号表示：$\omega_A X_A $当使用同态加密形式，则表示为：$[[\omega_A X_A ]]$

#### 算法执行流程

1. arbiter方分发公钥给A方和B方
2. B方计算$\omega_B X_B$，然后加密为$[[\omega_B X_B]]$。并且发给A方
3. A方收到$[[\omega_B X_B]]$后，同时自身也计算$[[\omega_A X_A]]$。然后获得完整的：$[[\omega x]] = [[\omega_A X_A]] + [[\omega_B X_B]]$
4. 这样，A方便获得了完整的关于每条数据的$d_i$。然后，将$d_i$发送给B方

经过上述的4个步骤，双方便分别确定了下式（密文状态下）：

对于A方而言：
$$
\nabla F(\omega)_A=\frac{1}{n}\sum_{n=1}^{n}(0.25 \omega^Tx-0.5y)x_A =\frac{1}{n}\sum_{n=1}^{n}d_ix_A
$$
对于B方而言：
$$
\nabla F(\omega)_B=\frac{1}{n}\sum_{n=1}^{n}(0.25 \omega^Tx-0.5y)x_B =\frac{1}{n}\sum_{n=1}^{n}d_ix_B
$$

5. A、B双方求出梯度（密文）后，开始发送给arbiter方。然后它来解密梯度，再发送给A方和B方
6. A方、B方收到解密的梯度后，开始更新模型参数$\omega_A和\omega_B$
7. 重复上述2~6过程，直到收敛或者达到指定的迭代次数



---

#### 隐私泄露风险

当使用同态加密的技术的时候，A方在当前批出会获得关于B的系列$w_B^Tx_B$。B方会获得关于A的$h(w_i,x_i,y_i)$系列信息。加入参与方存在攻击者的话，容易从中窃取用户隐私。已有论文已经证明这一点了

论文参考：

> 《exploiting unintended feature leakage in collaborative learning》
>
> 《model inversion attacks that exploit confidence information and basic countermeasures》

### 多方场景二：纵向逻辑回归（使用差分隐私技术去保护隐私）

> 这篇文章的参考链接如下：
>
> Hybrid Differentially Private Federated Learning on Vertically Partitioned Data

上述这篇文章有待于优化的就是全局敏感度容易太大，导致噪声太大，致使模型训练效果不太理想。这篇文章的主要思想如下：

预处理：将数据归一化到-1~1之间。然后开始如下迭代过程：

1. B方选择小批量数据集$X_t$(t代表当前的迭代次数)，然后计算$IR_t^B=X_t^B\omega_t^B$

添加噪声，公式为：$Sec[IR_t^B]=IR_t^B + Z^B$ 。这样，$Sec[IR_t^B]$就是添加噪声后的$IR_t^B$。而后将此结果发送给A方

> 疑问点：这里的$IR_t^B$是否是取均值后的结果，或者它就是当前批次的若干条数据。
>
> 我这里是当作**当前批次的若干条数据**来处理，给每条数据添加噪音。

2. 这样，A方就获得了完整的$\omega x = \omega_A X_A + \omega_B X_B$，只不过这里的$\omega_B X_B$添加了噪音。根据逻辑回归的整体损失函数，可以表示成(b代表的是当前的小批量)：

$$
\nabla F(\omega) = \sum_{n=1}^{b}(\frac{y_i}{1+e^{-y_i\omega^Tx_i}}-y_i)x_i=\sum_{n=1}^{b}d_ix_i
$$

在这里将$d_i$表示成$IR_t^A$。然后$IR_t^A$添加噪声，$Sec[IR_t^A]=IR_t^A + Z_A$。将这个结果发送给B方

3. 经过一轮交互之后，A方、B方各自获得：

$$
\nabla F(\omega)_A=\sum_{n=1}^{b}Sec[IR_t^A]x_A
$$

$$
\nabla F(\omega)_B=\sum_{n=1}^{b}Sec[IR_t^A]x_B
$$

4. 下面的就和常规的逻辑回归一样了，A、B双方得到各自的梯度，于是更新子模型：$\omega_A和\omega_B$
5. 重复1-4步骤便可。直到收敛或者达到指定的迭代次数

## 基于HE和DP技术的纵向联邦学习模型

本项目的完整GitHub地址如下（https://github.com/XtangEver/HDP-VFL）：

[项目github地址](https://github.com/XtangEver/HDP-VFL)

### B方添加的噪音

当A方计算出密文梯度：
$$
\nabla F(\omega)_A=\frac{1}{n}\sum_{n=1}^{n}(0.25 \omega^Tx-0.5y)x_A =\frac{1}{n}\sum_{n=1}^{n}d_ix_A
$$
需要将上述结果发送给B方，B方采用DP技术添加噪音（高斯噪声），其中全局敏感度的公式如下：
$$
\triangle f = \sqrt{\frac{4L^2e^2T\eta^2}{b}+\frac{8kLe^2\eta}{b}+4k^2e}
$$
在上述结果的基础上，我们假设所有的数据都已正则化到-1~1之间。那么任意改变一条记录，所会改变的数据的L2敏感度是：$\sqrt(n)$。其中n代表B方数据的维度信息，所以B所添加的噪音对应的全敏感度公式是：
$$
\triangle f = \sqrt{\frac{4L^2e^2T\eta^2}{b}+\frac{8kLe^2\eta}{b}+4k^2e}* \sqrt{n} / b
$$
其中参数所对应的含义如下：

```python 
    def gaussian(self,delta,epsilon,L,e,T,eta,b,k,length):
        """
        生成高斯噪声所需要的loc、sigma_a
        parameters
        --------------------
        delta:一定程度的允许错误的值，因为高斯机制非严格满足DP机制
        epsion:隐私保护预算
        L:lipschitz 常数，默认值为1
        e:epochs
        T:e * r,表示总的迭代次数
        eta:learning rate
        b:mini-batch size
        k:梯度剪切参数
        length:表述数据维度的长度

        loc,sigma都是高斯分布的俩参数
        """
        loc = 0
        partial_1 = np.sqrt(2 * np.log(1.25 / delta))
        partial_2_1 = (4 * np.square(L) * np.square(e) * T * np.square(eta)) / b
        partial_2_2 = (8 * k * L * np.square(e) * eta) / b
        partial_2_3 = 4 * np.square(k) * e
        partial_2 = np.sqrt(partial_2_1 + partial_2_2 + partial_2_3) * np.sqrt(length) / b #最大敏感度
        partial_3 = epsilon
        sigma_a = partial_1 * partial_2 / partial_3

        LOGGER.info("站在host方，全局敏感度值:{}".format(partial_2))
        LOGGER.info("站在host方，标准差是:{}".format(sigma_a))
        return loc,sigma_a
```

### A方添加的噪音

当B计算出密文梯度后:
$$
\nabla F(\omega)_B=\frac{1}{n}\sum_{n=1}^{n}(0.25 \omega^Tx-0.5y)x_B =\frac{1}{n}\sum_{n=1}^{n}d_ix_B
$$
需要将上述结果发送给A方，A方采用DP技术添加噪音（高斯噪声），其中全局敏感度的公式如下
$$
\triangle f = \sqrt{4\beta_{\theta}^2L^2\frac{e^2T\eta^2}{b}+8(\beta_{\theta
}k+\beta_yk_y)\beta_{\theta}L\frac{e^2\eta}{b}+4(\beta_\theta k+\beta_yk_y)^2e}
$$
当任意改变A中数据的一条记录，所会改变的数据的L2敏感度是$\sqrt(n)$。其中n代表A方数据的维度信息，所以B所添加的噪音对应的全敏感度公式是：
$$
\triangle f = \sqrt{4\beta_{\theta}^2L^2\frac{e^2T\eta^2}{b}+8(\beta_{\theta
}k+\beta_yk_y)\beta_{\theta}L\frac{e^2\eta}{b}+4(\beta_\theta k+\beta_yk_y)^2e} *　\sqrt{n} / b
$$
其中若干参数所对应的含义是：

```python 
    def gaussian(self,delta,epsilon,beta_theta,L,e,T,eta,b,k,beta_y,k_y,length):
        """
        生成高斯噪声所需要的loc、sigma_b
        parameters
        ---------------------------
        delta:非严格的DP损失
        epsilon:隐私保护预算
        beta_theta:smooth parameters,未知
        L:lipschitz 常数，默认值为1
        e:epochs
        T:e * r,表示总的迭代次数
        eta:learning rate
        b:mini-batch size
        k:梯度剪切参数
        beta_y:smooth parameters,未知
        k_y:target bound,未知
        length:host方数据的维度，作为全局敏感度的一个参数
        """
        loc = 0
        partial_1 = np.sqrt(2 * np.log(1.25 / delta))

        partial_2_1 = 4 * np.square(beta_theta) * np.square(L) * np.square(e) * T * np.square(eta) / b
        partial_2_2 = 8 * (beta_theta * k + beta_y * k_y) * beta_theta * L * np.square(e) * eta / b
        partial_2_3 = 4 * np.square(beta_theta * k + beta_y * k_y) * e
        partial_2 = np.sqrt(partial_2_1 + partial_2_2 + partial_2_3) * np.sqrt(length) / b #最大敏感度

        partial_3 = epsilon

        sigma_b = partial_1 * partial_2 / partial_3
        LOGGER.info("在guest方，全局敏感度值:{}".format(partial_2))
        LOGGER.info("在guest方，标准差sigma_b:{}".format(sigma_b))
        return loc,sigma_b
```

### 实验结果如下

#### 当不添加噪音的时候，只使用HE技术：

![Snipaste_2021-10-15_06-09-51](http://typora-xtang.oss-cn-beijing.aliyuncs.com/flceshi/Snipaste_2021-10-15_06-09-51.png)

#### 当添加高斯噪音后

![Snipaste_2021-10-15_06-08-55](http://typora-xtang.oss-cn-beijing.aliyuncs.com/flceshi/Snipaste_2021-10-15_06-08-55.png)

其中A方以及B方的全局敏感度以及噪音如下：

![Snipaste_2021-10-15_06-19-38](http://typora-xtang.oss-cn-beijing.aliyuncs.com/flceshi/Snipaste_2021-10-15_06-19-38.png)

![Snipaste_2021-10-15_06-18-26](http://typora-xtang.oss-cn-beijing.aliyuncs.com/flceshi/Snipaste_2021-10-15_06-18-26.png)

#### 总结

我们牺牲了非常小的精度，却换取了用户的隐私的保护强度提升。是很值得的！
